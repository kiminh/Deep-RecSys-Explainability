{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat,get_feature_names\n",
    "\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import  save_model,load_model\n",
    "from tensorflow.keras import layers\n",
    "from deepctr.layers import custom_objects\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import deque\n",
    "import random\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Time: 0.3611609935760498\n",
      "Shape: (10000, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>I11</th>\n",
       "      <th>I12</th>\n",
       "      <th>I13</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.009047</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.024676</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>75</td>\n",
       "      <td>193</td>\n",
       "      <td>5444</td>\n",
       "      <td>1955</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2766</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1954</td>\n",
       "      <td>1450</td>\n",
       "      <td>1120</td>\n",
       "      <td>266</td>\n",
       "      <td>3</td>\n",
       "      <td>1094</td>\n",
       "      <td>2529</td>\n",
       "      <td>8</td>\n",
       "      <td>1089</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1977</td>\n",
       "      <td>33</td>\n",
       "      <td>1147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>75</td>\n",
       "      <td>369</td>\n",
       "      <td>2401</td>\n",
       "      <td>1044</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1824</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>488</td>\n",
       "      <td>645</td>\n",
       "      <td>1979</td>\n",
       "      <td>1457</td>\n",
       "      <td>15</td>\n",
       "      <td>1813</td>\n",
       "      <td>3718</td>\n",
       "      <td>0</td>\n",
       "      <td>771</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1894</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>629</td>\n",
       "      <td>33</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.007315</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.033401</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>56</td>\n",
       "      <td>3073</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2498</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>682</td>\n",
       "      <td>775</td>\n",
       "      <td>2971</td>\n",
       "      <td>1152</td>\n",
       "      <td>2</td>\n",
       "      <td>866</td>\n",
       "      <td>1007</td>\n",
       "      <td>6</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4486</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>532</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75</td>\n",
       "      <td>64</td>\n",
       "      <td>3674</td>\n",
       "      <td>758</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>624</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2811</td>\n",
       "      <td>1867</td>\n",
       "      <td>3342</td>\n",
       "      <td>354</td>\n",
       "      <td>2</td>\n",
       "      <td>179</td>\n",
       "      <td>1557</td>\n",
       "      <td>1</td>\n",
       "      <td>522</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2078</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102</td>\n",
       "      <td>272</td>\n",
       "      <td>4311</td>\n",
       "      <td>3927</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2181</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>954</td>\n",
       "      <td>1869</td>\n",
       "      <td>2085</td>\n",
       "      <td>1628</td>\n",
       "      <td>3</td>\n",
       "      <td>1132</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1799</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.754524</td>\n",
       "      <td>0.008798</td>\n",
       "      <td>0.060941</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>4459</td>\n",
       "      <td>3164</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>1032</td>\n",
       "      <td>631</td>\n",
       "      <td>883</td>\n",
       "      <td>553</td>\n",
       "      <td>15</td>\n",
       "      <td>1659</td>\n",
       "      <td>429</td>\n",
       "      <td>6</td>\n",
       "      <td>1046</td>\n",
       "      <td>285</td>\n",
       "      <td>2</td>\n",
       "      <td>3578</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1969</td>\n",
       "      <td>30</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.032143</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.011730</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011688</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>3668</td>\n",
       "      <td>2517</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1652</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2706</td>\n",
       "      <td>1783</td>\n",
       "      <td>5227</td>\n",
       "      <td>1396</td>\n",
       "      <td>2</td>\n",
       "      <td>179</td>\n",
       "      <td>3613</td>\n",
       "      <td>7</td>\n",
       "      <td>522</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>595</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.066345</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.013770</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.278481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>128</td>\n",
       "      <td>102</td>\n",
       "      <td>778</td>\n",
       "      <td>2119</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1129</td>\n",
       "      <td>971</td>\n",
       "      <td>235</td>\n",
       "      <td>605</td>\n",
       "      <td>2</td>\n",
       "      <td>787</td>\n",
       "      <td>232</td>\n",
       "      <td>8</td>\n",
       "      <td>350</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1026</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1575</td>\n",
       "      <td>35</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>0.010264</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1774</td>\n",
       "      <td>1972</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1574</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>401</td>\n",
       "      <td>820</td>\n",
       "      <td>971</td>\n",
       "      <td>331</td>\n",
       "      <td>3</td>\n",
       "      <td>790</td>\n",
       "      <td>3507</td>\n",
       "      <td>8</td>\n",
       "      <td>879</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>383</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1336</td>\n",
       "      <td>1</td>\n",
       "      <td>1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>4318</td>\n",
       "      <td>499</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1842</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1408</td>\n",
       "      <td>2041</td>\n",
       "      <td>2734</td>\n",
       "      <td>1424</td>\n",
       "      <td>8</td>\n",
       "      <td>399</td>\n",
       "      <td>2357</td>\n",
       "      <td>8</td>\n",
       "      <td>179</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>4826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1651</td>\n",
       "      <td>1</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label        I1        I2        I3        I4        I5        I6  \\\n",
       "0         0  0.004673  0.000162  0.000076  0.000000  0.000854  0.000329   \n",
       "1         0  0.009346  0.000108  0.000671  0.003571  0.000063  0.000658   \n",
       "2         0  0.009346  0.000108  0.000015  0.050000  0.000474  0.007315   \n",
       "3         0  0.000000  0.048316  0.000000  0.000000  0.002714  0.000000   \n",
       "4         0  0.014019  0.000054  0.000000  0.000000  0.000001  0.000000   \n",
       "...     ...       ...       ...       ...       ...       ...       ...   \n",
       "9995      1  0.014019  0.000108  0.000092  0.007143  0.000420  0.000164   \n",
       "9996      1  0.004673  0.002267  0.000031  0.032143  0.000206  0.000822   \n",
       "9997      0  0.028037  0.001080  0.000046  0.017857  0.000003  0.001397   \n",
       "9998      1  0.028037  0.000216  0.000061  0.025000  0.000017  0.000575   \n",
       "9999      1  0.000000  0.000810  0.000092  0.014286  0.005372  0.005178   \n",
       "\n",
       "            I7        I8        I9       I10       I11       I12       I13  \\\n",
       "0     0.009047  0.002933  0.024676  0.166667  0.025316  0.000000  0.002597   \n",
       "1     0.001206  0.002933  0.000545  0.166667  0.012658  0.000000  0.005195   \n",
       "2     0.002413  0.002933  0.033401  0.166667  0.037975  0.030612  0.058442   \n",
       "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4     0.001809  0.000000  0.000000  0.166667  0.012658  0.000000  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  0.754524  0.008798  0.060941  0.166667  0.848101  0.010204  0.002597   \n",
       "9996  0.000603  0.011730  0.001363  0.166667  0.012658  0.000000  0.011688   \n",
       "9997  0.066345  0.005865  0.013770  0.333333  0.278481  0.000000  0.006494   \n",
       "9998  0.003619  0.010264  0.000954  0.166667  0.012658  0.000000  0.009091   \n",
       "9999  0.005428  0.005865  0.004363  0.000000  0.012658  0.000000  0.005195   \n",
       "\n",
       "       C1   C2    C3    C4  C5  C6    C7  C8  C9   C10   C11   C12   C13  C14  \\\n",
       "0      75  193  5444  1955   4   4  2766  12   2  1954  1450  1120   266    3   \n",
       "1      75  369  2401  1044   4   7  1824   4   2   488   645  1979  1457   15   \n",
       "2      18   18    56  3073   4   4  2498   4   2   682   775  2971  1152    2   \n",
       "3      75   64  3674   758   4   7   624   4   2  2811  1867  3342   354    2   \n",
       "4     102  272  4311  3927   4   1  2181   4   2   954  1869  2085  1628    3   \n",
       "...   ...  ...   ...   ...  ..  ..   ...  ..  ..   ...   ...   ...   ...  ...   \n",
       "9995    1   44  4459  3164  37   0   196  34   2  1032   631   883   553   15   \n",
       "9996    1   64  3668  2517   4   6  1652   4   2  2706  1783  5227  1396    2   \n",
       "9997  128  102   778  2119   4   4   400   4   2  1129   971   235   605    2   \n",
       "9998    1   80  1774  1972   4   0  1574   4   2   401   820   971   331    3   \n",
       "9999    1   46  4318   499   4   0  1842   4   2  1408  2041  2734  1424    8   \n",
       "\n",
       "       C15   C16  C17   C18  C19  C20   C21  C22  C23   C24  C25   C26  \n",
       "0     1094  2529    8  1089   64    3   148    0    1  1977   33  1147  \n",
       "1     1813  3718    0   771   64    1  1894    0    1   629   33   866  \n",
       "2      866  1007    6   234    0    0  4486    4    1   532    0     0  \n",
       "3      179  1557    1   522    0    0  2078    0    1  1445    0     0  \n",
       "4     1132    32    1   182    0    0   645    0    0  1799    0     0  \n",
       "...    ...   ...  ...   ...  ...  ...   ...  ...  ...   ...  ...   ...  \n",
       "9995  1659   429    6  1046  285    2  3578    0    7  1969   30   643  \n",
       "9996   179  3613    7   522    0    0   595    0    1  1445    0     0  \n",
       "9997   787   232    8   350   64    1  1026    6    0  1575   35   214  \n",
       "9998   790  3507    8   879   64    1   383    0    1  1336    1  1862  \n",
       "9999   399  2357    8   179   64    3  4826    0    0  1651    1  1531  \n",
       "\n",
       "[10000 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_row = ['label','I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13','C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14','C15','C16','C17','C18','C19','C20','C21','C22','C23','C24','C25','C26']\n",
    "\n",
    "start_load_time = time.time()\n",
    "data = pd.read_csv('../data/kaggle-display-advertising-challenge-dataset/train.txt', sep='\\t', names=header_row, nrows=10000)\n",
    "print(\"Loading Time:\",time.time()-start_load_time)\n",
    "\n",
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I'+str(i) for i in range(1, 14)]\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0,)\n",
    "target = ['label']\n",
    "\n",
    " # 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "    \n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])\n",
    "\n",
    "# 2.count #unique features for each sparse field,and record dense feature field name\n",
    "\n",
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].max() + 1, embedding_dim=4)\n",
    "                          for i, feat in enumerate(sparse_features)] + [DenseFeat(feat, 1, )\n",
    "                                                                        for feat in dense_features]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "    \n",
    "\n",
    "print(\"Shape:\",data.shape)\n",
    "\n",
    "pd.set_option('display.max_columns', len(data))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepFM_model = load_model('../models/DeepFM-01.h5',custom_objects)# load_model,just add a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_weights(DeepFM_model):\n",
    "    cat_weights = []\n",
    "    for category in sparse_features:\n",
    "        layer = 'sparse_emb_' + category\n",
    "        cat_weights.append(DeepFM_model.get_layer(layer).get_weights()[0])\n",
    "    for feat in cat_weights:\n",
    "        print(feat.shape)\n",
    "    return cat_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1391, 4)\n",
      "(544, 4)\n",
      "(863387, 4)\n",
      "(274717, 4)\n",
      "(290, 4)\n",
      "(19, 4)\n",
      "(11631, 4)\n",
      "(606, 4)\n",
      "(3, 4)\n",
      "(45638, 4)\n",
      "(5057, 4)\n",
      "(724685, 4)\n",
      "(3108, 4)\n",
      "(26, 4)\n",
      "(10845, 4)\n",
      "(533152, 4)\n",
      "(10, 4)\n",
      "(4461, 4)\n",
      "(2007, 4)\n",
      "(4, 4)\n",
      "(642071, 4)\n",
      "(17, 4)\n",
      "(15, 4)\n",
      "(74261, 4)\n",
      "(83, 4)\n",
      "(52069, 4)\n"
     ]
    }
   ],
   "source": [
    "DeepFM_model = load_model('../models/DeepFM-01.h5',custom_objects)\n",
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I'+str(i) for i in range(1, 14)]\n",
    "cat_weights = get_cat_weights(DeepFM_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train simple model to invert embedding vectors to integers\n",
    "\n",
    "for i in range(len(cat_weights)):\n",
    "    \n",
    "    train_indices = np.asarray(range(len(cat_weights[i])))\n",
    "    #train_labels = np.zeros((train_indices.size, train_indices.max()+1))\n",
    "    #train_labels[np.arange(train_indices.size),train_indices] = 1\n",
    "    train_labels = tf.one_hot(train_indices, len(train_indices), on_value=1, off_value=0, axis=-1)\n",
    "    print(\"Size:\", sys.getsizeof(train_labels))\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(4,)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(len(train_labels), activation='sigmoid')\n",
    "    ]) #outputs integer values for single categorical feature based on embedding vec, to be given to DeepFM\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.binary_crossentropy,\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "            tf.keras.metrics.Precision(name='precision'),\n",
    "            tf.keras.metrics.Recall(name='recall')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    history = model.fit(cat_weights[i], train_labels, epochs=10)\n",
    "    model_name = '../models/inverse_emb_models/inverse_emb_' + sparse_features[i] + '.h5'\n",
    "    save_model(model, model_name)# save inversion model for each categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.04160012,  0.0213794 ,  0.01748263, -0.00792122], dtype=float32), array([1., 0., 0., ..., 0., 0., 0.]))\n",
      "(array([-0.00556674,  0.01020092, -0.00246059,  0.00692831], dtype=float32), array([0., 1., 0., ..., 0., 0., 0.]))\n"
     ]
    }
   ],
   "source": [
    "def one_hot(cat_index):\n",
    "    index = 0\n",
    "    while index < len(cat_weights[cat_index]):\n",
    "        one_hot = np.zeros(len(cat_weights[cat_index]))\n",
    "        one_hot[index] = 1\n",
    "        yield cat_weights[cat_index][index], one_hot\n",
    "        index += 1\n",
    "        \n",
    "h1 = one_hot(0)\n",
    "print(next(h1))\n",
    "print(next(h1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1391, 4)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 11s 49ms/step - loss: 7.2377 - accuracy: 1.4966e-04 - precision: 7.8566e-04 - recall: 0.4867\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 7.2374 - accuracy: 0.0030 - precision: 9.5092e-04 - recall: 0.5618\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 7.2367 - accuracy: 0.0052 - precision: 0.0011 - recall: 0.5614\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 7.2345 - accuracy: 0.0048 - precision: 0.0013 - recall: 0.5329\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 7.2258 - accuracy: 0.0028 - precision: 0.0015 - recall: 0.4816\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 7.1907 - accuracy: 0.0021 - precision: 0.0015 - recall: 0.4392\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 12s 61ms/step - loss: 7.0914 - accuracy: 0.0015 - precision: 0.0015 - recall: 0.4382\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 11s 53ms/step - loss: 6.9493 - accuracy: 0.0015 - precision: 0.0016 - recall: 0.4874\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 6.8060 - accuracy: 0.0021 - precision: 0.0018 - recall: 0.5231\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 6.6512 - accuracy: 0.0022 - precision: 0.0018 - recall: 0.5121\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 6.5017 - accuracy: 0.0025 - precision: 0.0019 - recall: 0.4955\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 6.3637 - accuracy: 0.0034 - precision: 0.0019 - recall: 0.4868\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 6.2320 - accuracy: 0.0062 - precision: 0.0019 - recall: 0.4915\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 6.1063 - accuracy: 0.0103 - precision: 0.0020 - recall: 0.4930\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 5.9855 - accuracy: 0.0157 - precision: 0.0019 - recall: 0.4906\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 5.8712 - accuracy: 0.0160 - precision: 0.0020 - recall: 0.4949\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 5.7637 - accuracy: 0.0163 - precision: 0.0020 - recall: 0.4950\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 5.6635 - accuracy: 0.0186 - precision: 0.0020 - recall: 0.4955\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 5.5685 - accuracy: 0.0269 - precision: 0.0020 - recall: 0.4969\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 5.4772 - accuracy: 0.0304 - precision: 0.0021 - recall: 0.4982\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 5.3935 - accuracy: 0.0348 - precision: 0.0021 - recall: 0.4984\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 5.3130 - accuracy: 0.0369 - precision: 0.0021 - recall: 0.4974\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 5.2395 - accuracy: 0.0404 - precision: 0.0021 - recall: 0.4969\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 5.1659 - accuracy: 0.0448 - precision: 0.0021 - recall: 0.4964\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 5.0937 - accuracy: 0.0511 - precision: 0.0021 - recall: 0.4978\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 5.0276 - accuracy: 0.0558 - precision: 0.0021 - recall: 0.4991\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 4.9621 - accuracy: 0.0610 - precision: 0.0021 - recall: 0.4986\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 4.9012 - accuracy: 0.0657 - precision: 0.0021 - recall: 0.4968\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 4.8401 - accuracy: 0.0738 - precision: 0.0021 - recall: 0.4960\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 4.7814 - accuracy: 0.0819 - precision: 0.0021 - recall: 0.4981\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 4.7233 - accuracy: 0.0861 - precision: 0.0021 - recall: 0.4987\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 11s 53ms/step - loss: 4.6667 - accuracy: 0.0949 - precision: 0.0022 - recall: 0.4982 1s - loss: 4.6692 - accuracy: 0.0945 - precisi\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 4.6145 - accuracy: 0.1035 - precision: 0.0022 - recall: 0.4968\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 4.5610 - accuracy: 0.1099 - precision: 0.0022 - recall: 0.4962\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 4.5075 - accuracy: 0.1224 - precision: 0.0022 - recall: 0.4976\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 4.4575 - accuracy: 0.1326 - precision: 0.0022 - recall: 0.4990\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 4.4075 - accuracy: 0.1394 - precision: 0.0022 - recall: 0.4992\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 4.3605 - accuracy: 0.1471 - precision: 0.0022 - recall: 0.4968\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 4.3137 - accuracy: 0.1579 - precision: 0.0022 - recall: 0.4962\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 4.2667 - accuracy: 0.1660 - precision: 0.0022 - recall: 0.4976\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 4.2220 - accuracy: 0.1756 - precision: 0.0022 - recall: 0.4993\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 4.1756 - accuracy: 0.1870 - precision: 0.0022 - recall: 0.4978\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 4.1339 - accuracy: 0.1977 - precision: 0.0022 - recall: 0.4968 2s - loss: 4.1372 - accurac\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 11s 53ms/step - loss: 4.0936 - accuracy: 0.2084 - precision: 0.0022 - recall: 0.4969\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 10s 52ms/step - loss: 4.0490 - accuracy: 0.2149 - precision: 0.0022 - recall: 0.4969\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 4.0070 - accuracy: 0.2255 - precision: 0.0023 - recall: 0.4984\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 3.9679 - accuracy: 0.2341 - precision: 0.0023 - recall: 0.4987\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 15s 75ms/step - loss: 3.9281 - accuracy: 0.2435 - precision: 0.0023 - recall: 0.4983\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 3.8913 - accuracy: 0.2514 - precision: 0.0023 - recall: 0.4976\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 3.8511 - accuracy: 0.2579 - precision: 0.0023 - recall: 0.4971\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "#train_indices = np.asarray(range(len(cat_weights[i])))\n",
    "#train_labels = np.zeros((train_indices.size, train_indices.max()+1))\n",
    "#train_labels[np.arange(train_indices.size),train_indices] = 1\n",
    "\n",
    "#train_labels = one_hot(len(cat_weights[i]))\n",
    "batch_size = 256\n",
    "len_one_hot = len(cat_weights[i])\n",
    "generator = create_one_hot(i)\n",
    "dataset = tf.data.Dataset.from_generator(generator, (tf.float32, tf.int32), ((4, ), (len_one_hot,)))\n",
    "dataset = dataset.repeat().batch(batch_size)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(len_one_hot, activation='sigmoid')\n",
    "]) #outputs integer values for single categorical feature based on embedding vec, to be given to DeepFM\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.00001),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "STEPS_PER_EPOCH = 200\n",
    "#history = model.fit(cat_weights[i], train_labels, epochs=10)\n",
    "history = model.fit_generator(dataset, epochs=50, steps_per_epoch=STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3423330783843994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "correct = 0\n",
    "#for i in range(len(cat_weights[0])):\n",
    "for i in range(10):\n",
    "    pred = np.argmax(model.predict(cat_weights[0][i].reshape(1,-1)))\n",
    "    if pred == i:\n",
    "        correct +=1\n",
    "\n",
    "print(time.time() - start)\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(cat_weights[0][4].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0384221076965332\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.predict(cat_weights[0][i].reshape(1,-1))\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04160012,  0.0213794 ,  0.01748263, -0.00792122], dtype=float32)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_weights[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "ValueError: `generator` yielded an element of shape (4,) where an element of shape (1391, 4) was expected.\nTraceback (most recent call last):\n\n  File \"/Users/sean/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/Users/sean/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/sean/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 938, in generator_py_func\n    (ret_array.shape, expected_shape))\n\nValueError: `generator` yielded an element of shape (4,) where an element of shape (1391, 4) was expected.\n\n\n\t [[{{node PyFunc}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2112\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2114\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2579\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2580\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ValueError: `generator` yielded an element of shape (4,) where an element of shape (1391, 4) was expected.\nTraceback (most recent call last):\n\n  File \"/Users/sean/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/Users/sean/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/sean/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 938, in generator_py_func\n    (ret_array.shape, expected_shape))\n\nValueError: `generator` yielded an element of shape (4,) where an element of shape (1391, 4) was expected.\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-57321f147af7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monehot_vec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Verify the shapes are still as we expect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input shape is:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output shape is:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monehot_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Print the first element and the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3941\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3942\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3944\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2114\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2116\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ValueError: `generator` yielded an element of shape (4,) where an element of shape (1391, 4) was expected.\nTraceback (most recent call last):\n\n  File \"/Users/sean/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/Users/sean/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/sean/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 938, in generator_py_func\n    (ret_array.shape, expected_shape))\n\nValueError: `generator` yielded an element of shape (4,) where an element of shape (1391, 4) was expected.\n\n\n\t [[{{node PyFunc}}]]"
     ]
    }
   ],
   "source": [
    "for emb, onehot_vec in dataset.as_numpy_iterator():\n",
    "    # Verify the shapes are still as we expect\n",
    "    print(\"Input shape is:\", emb.shape, \"output shape is:\", onehot_vec.shape)\n",
    "\n",
    "    # Print the first element and the label\n",
    "    plt.imshow(emb[0,:])\n",
    "    plt.show()\n",
    "    print('label of this input is', onehot_vec[0])\n",
    "    \n",
    "    # Break now. We only want to visualise the first example\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(stop):\n",
    "    i = 0\n",
    "    while i<stop:\n",
    "        yield i\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[10 11 12 13 14 15 16 17 18 19]\n",
      "[20 21 22 23 24  0  1  2  3  4]\n",
      "[ 5  6  7  8  9 10 11 12 13 14]\n",
      "[15 16 17 18 19 20 21 22 23 24]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[10 11 12 13 14 15 16 17 18 19]\n",
      "[20 21 22 23 24  0  1  2  3  4]\n",
      "[ 5  6  7  8  9 10 11 12 13 14]\n",
      "[15 16 17 18 19 20 21 22 23 24]\n"
     ]
    }
   ],
   "source": [
    "ds_counter = tf.data.Dataset.from_generator(count, args=[25], output_types=tf.int32, output_shapes = (), )\n",
    "\n",
    "for count_batch in ds_counter.repeat().batch(10).take(10):\n",
    "    print(count_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 0 0 0 0 0 0 0 0 0], shape=(10,), dtype=int32)\n",
      "tf.Tensor([0 1 0 0 0 0 0 0 0 0], shape=(10,), dtype=int32)\n",
      "tf.Tensor([0 0 1 0 0 0 0 0 0 0], shape=(10,), dtype=int32)\n",
      "tf.Tensor([0 0 0 1 0 0 0 0 0 0], shape=(10,), dtype=int32)\n",
      "tf.Tensor([0 0 0 0 1 0 0 0 0 0], shape=(10,), dtype=int32)\n",
      "tf.Tensor([0 0 0 0 0 1 0 0 0 0], shape=(10,), dtype=int32)\n",
      "tf.Tensor([0 0 0 0 0 0 1 0 0 0], shape=(10,), dtype=int32)\n",
      "tf.Tensor([0 0 0 0 0 0 0 1 0 0], shape=(10,), dtype=int32)\n",
      "tf.Tensor([0 0 0 0 0 0 0 0 1 0], shape=(10,), dtype=int32)\n",
      "tf.Tensor([0 0 0 0 0 0 0 0 0 1], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "len_vec = 10\n",
    "one_hot_gen = tf.data.Dataset.from_generator(one_hot, args=[len_vec], output_types=tf.int32, output_shapes = (len_vec), )\n",
    "\n",
    "for vector in one_hot_gen.repeat().take(len_vec):\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_generator(inputs, labels):\n",
    "    def argument_free_generator():\n",
    "        for inp, label in zip(inputs, labels):\n",
    "            yield inp, label\n",
    "    return argument_free_generator\n",
    "\n",
    "# Create the generator which yields inputs and outputs\n",
    "generator = create_dataset_generator(x_train, y_train)\n",
    "\n",
    "# Create the tf.data.Dataset from this generator and specify the types and shapes of the data. \n",
    "dataset = tf.data.Dataset.from_generator(generator, (tf.float32, tf.int32), ((28,28 ), ()))\n",
    "\n",
    "# By default you 'run out of data', this is why you repeat the dataset and serve data in batches. \n",
    "dataset = dataset.repeat().batch(BATCH_SIZE)\n",
    "\n",
    "# Train for one epoch to verify this works. \n",
    "model = get_and_compile_model()\n",
    "model.fit(dataset,steps_per_epoch=STEPS_PER_EPOCH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hot(cat_index):\n",
    "    def one_hot():\n",
    "        index = 0\n",
    "        while index < len(cat_weights[cat_index]):\n",
    "            one_hot = np.zeros(len(cat_weights[cat_index]))\n",
    "            one_hot[index] = 1\n",
    "            yield cat_weights[cat_index][index], one_hot\n",
    "            index += 1\n",
    "    return one_hot\n",
    "\n",
    "i = 0\n",
    "batch_size = 256\n",
    "len_one_hot = len(cat_weights[i])\n",
    "generator = create_one_hot(i)\n",
    "dataset = tf.data.Dataset.from_generator(generator, (tf.float32, tf.int32), ((4, ), (len_one_hot,)))\n",
    "dataset = dataset.repeat().batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataset.as_numpy_iterator())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(generator, (tf.float32, tf.int32), ((28,28 ), ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['p', 'a', 'h', 'n'], ['a', 'p', 'l', 's', 'i', 'i', 'g'], ['y', 'i', 'r']]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'paypalishiring'\n",
    "nrows = 3\n",
    "lists = []\n",
    "for i in range(nrows):\n",
    "    lists.append([])\n",
    "\n",
    "for i in range(len(s)):\n",
    "    if i % 4 == 0:\n",
    "        lists[0] += s[i]\n",
    "        \n",
    "    if i % 4 == 1 or i % 4 == 3:\n",
    "        lists[1] += s[i]\n",
    "        \n",
    "    if i % 4 == 2:\n",
    "        lists[2] += s[i]\n",
    "        \n",
    "lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
