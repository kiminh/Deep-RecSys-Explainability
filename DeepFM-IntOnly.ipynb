{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat,get_feature_names\n",
    "\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import  save_model,load_model\n",
    "from deepctr.layers import custom_objects\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Time: 18.466125011444092\n",
      "Shape: (3000000, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>I11</th>\n",
       "      <th>I12</th>\n",
       "      <th>I13</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.442957e-04</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>604</td>\n",
       "      <td>268</td>\n",
       "      <td>848553</td>\n",
       "      <td>132728</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>10058</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>29947</td>\n",
       "      <td>3564</td>\n",
       "      <td>158090</td>\n",
       "      <td>474</td>\n",
       "      <td>4</td>\n",
       "      <td>5888</td>\n",
       "      <td>285899</td>\n",
       "      <td>9</td>\n",
       "      <td>4253</td>\n",
       "      <td>249</td>\n",
       "      <td>3</td>\n",
       "      <td>19417</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>57441</td>\n",
       "      <td>69</td>\n",
       "      <td>30715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>4.017233e-05</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>604</td>\n",
       "      <td>514</td>\n",
       "      <td>375982</td>\n",
       "      <td>70110</td>\n",
       "      <td>43</td>\n",
       "      <td>18</td>\n",
       "      <td>6686</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>7715</td>\n",
       "      <td>1540</td>\n",
       "      <td>278311</td>\n",
       "      <td>2629</td>\n",
       "      <td>17</td>\n",
       "      <td>9756</td>\n",
       "      <td>418883</td>\n",
       "      <td>0</td>\n",
       "      <td>3043</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "      <td>243203</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19648</td>\n",
       "      <td>69</td>\n",
       "      <td>23237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.024955</td>\n",
       "      <td>3.020802e-04</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.012677</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.006542</td>\n",
       "      <td>219</td>\n",
       "      <td>25</td>\n",
       "      <td>9426</td>\n",
       "      <td>208134</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>9042</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>10480</td>\n",
       "      <td>1858</td>\n",
       "      <td>407308</td>\n",
       "      <td>2102</td>\n",
       "      <td>2</td>\n",
       "      <td>4660</td>\n",
       "      <td>112485</td>\n",
       "      <td>6</td>\n",
       "      <td>876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>575361</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>17088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.729773e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>604</td>\n",
       "      <td>96</td>\n",
       "      <td>572327</td>\n",
       "      <td>49409</td>\n",
       "      <td>43</td>\n",
       "      <td>18</td>\n",
       "      <td>2155</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>42827</td>\n",
       "      <td>4544</td>\n",
       "      <td>461549</td>\n",
       "      <td>656</td>\n",
       "      <td>2</td>\n",
       "      <td>1003</td>\n",
       "      <td>172219</td>\n",
       "      <td>1</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>268935</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>41965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.876928e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>785</td>\n",
       "      <td>381</td>\n",
       "      <td>675033</td>\n",
       "      <td>267410</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>7919</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>14642</td>\n",
       "      <td>4560</td>\n",
       "      <td>290726</td>\n",
       "      <td>2935</td>\n",
       "      <td>4</td>\n",
       "      <td>6063</td>\n",
       "      <td>3466</td>\n",
       "      <td>1</td>\n",
       "      <td>659</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84436</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>51947</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.048097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.981047e-04</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>527</td>\n",
       "      <td>123</td>\n",
       "      <td>435525</td>\n",
       "      <td>143822</td>\n",
       "      <td>106</td>\n",
       "      <td>7</td>\n",
       "      <td>7062</td>\n",
       "      <td>216</td>\n",
       "      <td>2</td>\n",
       "      <td>8262</td>\n",
       "      <td>3672</td>\n",
       "      <td>197215</td>\n",
       "      <td>2931</td>\n",
       "      <td>9</td>\n",
       "      <td>833</td>\n",
       "      <td>531960</td>\n",
       "      <td>0</td>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>326506</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.006671e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>325</td>\n",
       "      <td>149572</td>\n",
       "      <td>143037</td>\n",
       "      <td>106</td>\n",
       "      <td>9</td>\n",
       "      <td>4974</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>4609</td>\n",
       "      <td>1873</td>\n",
       "      <td>703940</td>\n",
       "      <td>904</td>\n",
       "      <td>4</td>\n",
       "      <td>5423</td>\n",
       "      <td>225248</td>\n",
       "      <td>9</td>\n",
       "      <td>730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65868</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>41860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.938464e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>268</td>\n",
       "      <td>678675</td>\n",
       "      <td>119601</td>\n",
       "      <td>43</td>\n",
       "      <td>18</td>\n",
       "      <td>6818</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>10480</td>\n",
       "      <td>2263</td>\n",
       "      <td>492343</td>\n",
       "      <td>2715</td>\n",
       "      <td>17</td>\n",
       "      <td>2182</td>\n",
       "      <td>349245</td>\n",
       "      <td>5</td>\n",
       "      <td>3840</td>\n",
       "      <td>249</td>\n",
       "      <td>3</td>\n",
       "      <td>237220</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6767</td>\n",
       "      <td>69</td>\n",
       "      <td>23797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.586059e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>490018</td>\n",
       "      <td>263330</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>4792</td>\n",
       "      <td>397</td>\n",
       "      <td>2</td>\n",
       "      <td>10480</td>\n",
       "      <td>2093</td>\n",
       "      <td>492789</td>\n",
       "      <td>290</td>\n",
       "      <td>2</td>\n",
       "      <td>2809</td>\n",
       "      <td>389375</td>\n",
       "      <td>9</td>\n",
       "      <td>1812</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10497</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>55990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>2.993233e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>30</td>\n",
       "      <td>68</td>\n",
       "      <td>443174</td>\n",
       "      <td>2731</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>695</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>21560</td>\n",
       "      <td>3344</td>\n",
       "      <td>108422</td>\n",
       "      <td>2875</td>\n",
       "      <td>17</td>\n",
       "      <td>2583</td>\n",
       "      <td>237754</td>\n",
       "      <td>3</td>\n",
       "      <td>967</td>\n",
       "      <td>249</td>\n",
       "      <td>3</td>\n",
       "      <td>574524</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2400</td>\n",
       "      <td>1</td>\n",
       "      <td>4554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label        I1        I2        I3        I4            I5  \\\n",
       "0            0  0.000827  0.000216  0.000076  0.000000  5.442957e-04   \n",
       "1            0  0.001654  0.000162  0.000671  0.001783  4.017233e-05   \n",
       "2            0  0.001654  0.000162  0.000015  0.024955  3.020802e-04   \n",
       "3            0  0.000000  0.048367  0.000000  0.000000  1.729773e-03   \n",
       "4            0  0.002481  0.000108  0.000000  0.000000  7.876928e-07   \n",
       "...        ...       ...       ...       ...       ...           ...   \n",
       "2999995      1  0.000827  0.048097  0.000000  0.000000  1.981047e-04   \n",
       "2999996      1  0.000000  0.000108  0.000000  0.000000  1.006671e-03   \n",
       "2999997      1  0.000000  0.000108  0.000000  0.000000  3.938464e-06   \n",
       "2999998      0  0.000000  0.000486  0.000000  0.000000  1.586059e-02   \n",
       "2999999      0  0.001654  0.000216  0.000061  0.001783  2.993233e-05   \n",
       "\n",
       "               I6        I7        I8        I9    I10       I11       I12  \\\n",
       "0        0.000017  0.000570  0.000395  0.009365  0.125  0.012903  0.000000   \n",
       "1        0.000034  0.000076  0.000395  0.000207  0.125  0.006452  0.000000   \n",
       "2        0.000381  0.000152  0.000395  0.012677  0.125  0.019355  0.002333   \n",
       "3        0.000000  0.000000  0.000000  0.000000  0.000  0.000000  0.000000   \n",
       "4        0.000000  0.000114  0.000000  0.000000  0.125  0.006452  0.000000   \n",
       "...           ...       ...       ...       ...    ...       ...       ...   \n",
       "2999995  0.000150  0.000304  0.000197  0.000103  0.125  0.019355  0.000000   \n",
       "2999996  0.000000  0.000761  0.000000  0.000000  0.000  0.006452  0.000000   \n",
       "2999997  0.000000  0.000000  0.000000  0.000000  0.000  0.000000  0.000000   \n",
       "2999998  0.000000  0.000000  0.004344  0.000517  0.000  0.000000  0.000000   \n",
       "2999999  0.000004  0.000076  0.000197  0.000052  0.125  0.006452  0.000000   \n",
       "\n",
       "              I13   C1   C2      C3      C4   C5  C6     C7   C8  C9    C10  \\\n",
       "0        0.000291  604  268  848553  132728   43   7  10058   79   2  29947   \n",
       "1        0.000581  604  514  375982   70110   43  18   6686   23   2   7715   \n",
       "2        0.006542  219   25    9426  208134   43   7   9042   23   2  10480   \n",
       "3        0.000000  604   96  572327   49409   43  18   2155   23   2  42827   \n",
       "4        0.000000  785  381  675033  267410   43   2   7919   23   2  14642   \n",
       "...           ...  ...  ...     ...     ...  ...  ..    ...  ...  ..    ...   \n",
       "2999995  0.000000  527  123  435525  143822  106   7   7062  216   2   8262   \n",
       "2999996  0.000000   30  325  149572  143037  106   9   4974   23   2   4609   \n",
       "2999997  0.000000   30  268  678675  119601   43  18   6818   23   0  10480   \n",
       "2999998  0.000000   30   20  490018  263330   43   7   4792  397   2  10480   \n",
       "2999999  0.000145   30   68  443174    2731   43   7    695   23   2  21560   \n",
       "\n",
       "          C11     C12   C13  C14   C15     C16  C17   C18  C19  C20     C21  \\\n",
       "0        3564  158090   474    4  5888  285899    9  4253  249    3   19417   \n",
       "1        1540  278311  2629   17  9756  418883    0  3043  249    1  243203   \n",
       "2        1858  407308  2102    2  4660  112485    6   876    0    0  575361   \n",
       "3        4544  461549   656    2  1003  172219    1  1995    0    0  268935   \n",
       "4        4560  290726  2935    4  6063    3466    1   659    0    0   84436   \n",
       "...       ...     ...   ...  ...   ...     ...  ...   ...  ...  ...     ...   \n",
       "2999995  3672  197215  2931    9   833  531960    0   792    0    0  326506   \n",
       "2999996  1873  703940   904    4  5423  225248    9   730    0    0   65868   \n",
       "2999997  2263  492343  2715   17  2182  349245    5  3840  249    3  237220   \n",
       "2999998  2093  492789   290    2  2809  389375    9  1812    0    0   10497   \n",
       "2999999  3344  108422  2875   17  2583  237754    3   967  249    3  574524   \n",
       "\n",
       "         C22  C23    C24  C25    C26  \n",
       "0          0    3  57441   69  30715  \n",
       "1          0    3  19648   69  23237  \n",
       "2         11    3  17088    0      0  \n",
       "3          0    3  41965    0      0  \n",
       "4          0    2  51947    0      0  \n",
       "...      ...  ...    ...  ...    ...  \n",
       "2999995    0    2   5344    0      0  \n",
       "2999996   10    8  41860    0      0  \n",
       "2999997    0   11   6767   69  23797  \n",
       "2999998    0    5  55990    0      0  \n",
       "2999999    0    3   2400    1   4554  \n",
       "\n",
       "[3000000 rows x 40 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_row = ['label','I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13','C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14','C15','C16','C17','C18','C19','C20','C21','C22','C23','C24','C25','C26']\n",
    "\n",
    "start_load_time = time.time()\n",
    "data = pd.read_csv('data/kaggle-display-advertising-challenge-dataset/train.txt', sep='\\t', names=header_row, nrows=3000000)\n",
    "print(\"Loading Time:\",time.time()-start_load_time)\n",
    "\n",
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I'+str(i) for i in range(1, 14)]\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0,)\n",
    "target = ['label']\n",
    "\n",
    " # 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "    \n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])\n",
    "\n",
    "# 2.count #unique features for each sparse field,and record dense feature field name\n",
    "\n",
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].max() + 1, embedding_dim=4)\n",
    "                          for i, feat in enumerate(sparse_features)] + [DenseFeat(feat, 1, )\n",
    "                                                                        for feat in dense_features]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "    \n",
    "\n",
    "print(\"Shape:\",data.shape)\n",
    "\n",
    "pd.set_option('display.max_columns', len(data))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process features for Pure Brute Force Method\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3000000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>C1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.442957e-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>4.017233e-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.024955</td>\n",
       "      <td>3.020802e-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.729773e-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.876928e-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.048097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.981047e-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.006671e-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.938464e-06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.586059e-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>2.993233e-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label        I1        I2        I3        I4            I5  C1\n",
       "0            0  0.000827  0.000216  0.000076  0.000000  5.442957e-04   0\n",
       "1            0  0.001654  0.000162  0.000671  0.001783  4.017233e-05   0\n",
       "2            0  0.001654  0.000162  0.000015  0.024955  3.020802e-04   0\n",
       "3            0  0.000000  0.048367  0.000000  0.000000  1.729773e-03   0\n",
       "4            0  0.002481  0.000108  0.000000  0.000000  7.876928e-07   0\n",
       "...        ...       ...       ...       ...       ...           ...  ..\n",
       "2999995      1  0.000827  0.048097  0.000000  0.000000  1.981047e-04   0\n",
       "2999996      1  0.000000  0.000108  0.000000  0.000000  1.006671e-03   0\n",
       "2999997      1  0.000000  0.000108  0.000000  0.000000  3.938464e-06   0\n",
       "2999998      0  0.000000  0.000486  0.000000  0.000000  1.586059e-02   0\n",
       "2999999      0  0.001654  0.000216  0.000061  0.001783  2.993233e-05   0\n",
       "\n",
       "[3000000 rows x 7 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_data = data.copy()\n",
    "\n",
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I'+str(i) for i in range(1, 14)]\n",
    "\n",
    "trunc_data = trunc_data.drop(columns=dense_features[5:])\n",
    "trunc_data = trunc_data.drop(columns=sparse_features[1:])\n",
    "trunc_data['C1'] = pd.DataFrame(np.array(['' for _ in range(len(trunc_data['C1']))]))\n",
    "\n",
    "dense_features = ['I'+str(i) for i in range(1, 6)] #I 1-5\n",
    "sparse_features = ['C' + str(i) for i in range(1, 2)]\n",
    "\n",
    "\n",
    "trunc_data[sparse_features] = trunc_data[sparse_features].fillna('-1', )\n",
    "trunc_data[dense_features] = trunc_data[dense_features].fillna(0,)\n",
    "target = ['label']\n",
    "\n",
    " # 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    trunc_data[feat] = lbe.fit_transform(trunc_data[feat])\n",
    "    \n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "trunc_data[dense_features] = mms.fit_transform(trunc_data[dense_features])\n",
    "\n",
    "# 2.count #unique features for each sparse field,and record dense feature field name\n",
    "\n",
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=trunc_data[feat].max() + 1, embedding_dim=4)\n",
    "                          for i, feat in enumerate(sparse_features)] + [DenseFeat(feat, 1, )\n",
    "                                                                        for feat in dense_features]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "    \n",
    "\n",
    "print(\"Shape:\",trunc_data.shape)\n",
    "\n",
    "pd.set_option('display.max_columns', len(trunc_data))\n",
    "trunc_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the training samples and train the model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7500/7500 [==============================] - 26s 3ms/step - loss: 0.5434 - binary_crossentropy: 0.5433 - val_loss: 0.5356 - val_binary_crossentropy: 0.5356\n",
      "Epoch 2/20\n",
      "7500/7500 [==============================] - 22s 3ms/step - loss: 0.5338 - binary_crossentropy: 0.5338 - val_loss: 0.5347 - val_binary_crossentropy: 0.5347\n",
      "Epoch 3/20\n",
      "7500/7500 [==============================] - 20s 3ms/step - loss: 0.5334 - binary_crossentropy: 0.5334 - val_loss: 0.5327 - val_binary_crossentropy: 0.5327\n",
      "Epoch 4/20\n",
      "7500/7500 [==============================] - 29s 4ms/step - loss: 0.5328 - binary_crossentropy: 0.5328 - val_loss: 0.5361 - val_binary_crossentropy: 0.5361\n",
      "Epoch 5/20\n",
      "7500/7500 [==============================] - 29s 4ms/step - loss: 0.5325 - binary_crossentropy: 0.5325 - val_loss: 0.5321 - val_binary_crossentropy: 0.5321\n",
      "Epoch 6/20\n",
      "7500/7500 [==============================] - 44s 6ms/step - loss: 0.5326 - binary_crossentropy: 0.5326 - val_loss: 0.5317 - val_binary_crossentropy: 0.5317\n",
      "Epoch 7/20\n",
      "7500/7500 [==============================] - 42s 6ms/step - loss: 0.5315 - binary_crossentropy: 0.5315 - val_loss: 0.5316 - val_binary_crossentropy: 0.5316\n",
      "Epoch 8/20\n",
      "7500/7500 [==============================] - 45s 6ms/step - loss: 0.5322 - binary_crossentropy: 0.5322 - val_loss: 0.5307 - val_binary_crossentropy: 0.5307\n",
      "Epoch 9/20\n",
      "7500/7500 [==============================] - 43s 6ms/step - loss: 0.5315 - binary_crossentropy: 0.5315 - val_loss: 0.5310 - val_binary_crossentropy: 0.5310\n",
      "Epoch 10/20\n",
      "7500/7500 [==============================] - 39s 5ms/step - loss: 0.5309 - binary_crossentropy: 0.5309 - val_loss: 0.5301 - val_binary_crossentropy: 0.5301\n",
      "Epoch 11/20\n",
      "7500/7500 [==============================] - 42s 6ms/step - loss: 0.5305 - binary_crossentropy: 0.5305 - val_loss: 0.5297 - val_binary_crossentropy: 0.5297\n",
      "Epoch 12/20\n",
      "7500/7500 [==============================] - 45s 6ms/step - loss: 0.5305 - binary_crossentropy: 0.5305 - val_loss: 0.5293 - val_binary_crossentropy: 0.5293\n",
      "Epoch 13/20\n",
      "7500/7500 [==============================] - 43s 6ms/step - loss: 0.5295 - binary_crossentropy: 0.5294 - val_loss: 0.5283 - val_binary_crossentropy: 0.5283\n",
      "Epoch 14/20\n",
      "7500/7500 [==============================] - 42s 6ms/step - loss: 0.5297 - binary_crossentropy: 0.5297 - val_loss: 0.5310 - val_binary_crossentropy: 0.5310\n",
      "Epoch 15/20\n",
      "7500/7500 [==============================] - 49s 6ms/step - loss: 0.5289 - binary_crossentropy: 0.5289 - val_loss: 0.5279 - val_binary_crossentropy: 0.5279\n",
      "Epoch 16/20\n",
      "7500/7500 [==============================] - 42s 6ms/step - loss: 0.5279 - binary_crossentropy: 0.5279 - val_loss: 0.5276 - val_binary_crossentropy: 0.5276\n",
      "Epoch 17/20\n",
      "7500/7500 [==============================] - 40s 5ms/step - loss: 0.5284 - binary_crossentropy: 0.5284 - val_loss: 0.5281 - val_binary_crossentropy: 0.5281\n",
      "Epoch 18/20\n",
      "7500/7500 [==============================] - 51s 7ms/step - loss: 0.5276 - binary_crossentropy: 0.5276 - val_loss: 0.5269 - val_binary_crossentropy: 0.5269\n",
      "Epoch 19/20\n",
      "7500/7500 [==============================] - 43s 6ms/step - loss: 0.5275 - binary_crossentropy: 0.5275 - val_loss: 0.5271 - val_binary_crossentropy: 0.5271\n",
      "Epoch 20/20\n",
      "7500/7500 [==============================] - 57s 8ms/step - loss: 0.5281 - binary_crossentropy: 0.5281 - val_loss: 0.5276 - val_binary_crossentropy: 0.5276\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(trunc_data, test_size=0.2)\n",
    "\n",
    "train_model_input = {name:train[name].values for name in feature_names}\n",
    "test_model_input = {name:test[name].values for name in feature_names}\n",
    "\n",
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary')\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=['binary_crossentropy'], )\n",
    "\n",
    "history = model.fit(train_model_input, train[target].values,\n",
    "                    batch_size=256, epochs=20, verbose=1, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff155a1b690>]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE 0.1741\n",
      "test LogLoss 0.5271\n",
      "test AUC 0.6736\n"
     ]
    }
   ],
   "source": [
    "pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "print(\"test MSE\", round(mean_squared_error(test[target].values, pred_ans), 4))\n",
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18750/18750 [==============================] - 31s 2ms/step - loss: 6.3585e-07 - binary_crossentropy: 0.0000e+00\n",
      "[6.358500286296476e-07, 0.0]\n"
     ]
    }
   ],
   "source": [
    "eval_result = model.evaluate(test_model_input)\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7519033333333334\n"
     ]
    }
   ],
   "source": [
    "true_pos = 0\n",
    "true_neg = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "\n",
    "for sample_i in range(len(pred_ans)):\n",
    "    if round(pred_ans[sample_i][0]) == test.label.iloc[sample_i]: # Predicted == Actual\n",
    "        if test.label.iloc[sample_i] == 1:\n",
    "            true_pos += 1\n",
    "        else:\n",
    "            true_neg += 1\n",
    "    else:\n",
    "        if test.label.iloc[sample_i] == 1:\n",
    "            false_neg += 1\n",
    "        else:\n",
    "            false_pos += 1\n",
    "\n",
    "accuracy = (true_pos + true_neg) / len(pred_ans)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'DeepFMint.h5')# save_model, same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('DeepFMint.h5',custom_objects)# load_model,just add a parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize BFET and query rec\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 10, 10)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_features = ['I1','I2','I3','I4','I5']\n",
    "rec_space_dim = 10\n",
    "ndims = len(dense_features)\n",
    "bfet_shape = (rec_space_dim,) * ndims\n",
    "bfet = np.ndarray(bfet_shape)\n",
    "bfet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "queryrec_feats = np.asarray([0,20,90,75,50,0])\n",
    "queryrec_input = {feature_names[name]:np.asarray([queryrec_feats[name]]) for name in range(len(feature_names))}\n",
    "queryrec_val = int(model.predict(queryrec_input))\n",
    "print(queryrec_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
